# ğŸ¤– AI Agent with Wikipedia Tool using n8n + Ollama (LangChain)

An AI-powered autonomous agent built using **n8n**, **LangChain Code Nodes**, and **Ollama (Mistral model)**.  
The agent can answer natural language questions and dynamically use a custom-built Wikipedia tool.

This project demonstrates real-world AI workflow automation using local LLM deployment via Docker.

---

## ğŸš€ Tech Stack

- **n8n** â€“ Workflow Automation Platform  
- **LangChain** â€“ AI orchestration framework  
- **Ollama** â€“ Local LLM runtime  
- **Mistral Model** â€“ Open-source LLM  
- **Docker & Docker Compose** â€“ Containerized deployment  
- **JavaScript (Code Nodes)** â€“ Custom LLM chain + tool logic  

---

## ğŸ§  Project Architecture

The workflow consists of:

1. Manual Trigger
2. Set Node (User Input)
3. Custom LLM Chain Node
4. Ollama Chat Model (mistral:latest)
5. LangChain Agent
6. Custom Wikipedia Tool Node

The agent:
- Receives a user question
- Decides whether to use a tool
- Calls the custom Wikipedia tool
- Returns a structured final answer

---

## ğŸ“¸ Workflow Overview

![Workflow](screenshots/workflow.png)

---

## ğŸ“¸ Model Output (Ollama - Mistral)

![Model Output](screenshots/ollama-mistral-model-output.png)

---

## âš™ï¸ How to Run Locally

### 1ï¸âƒ£ Install Requirements

- Docker Desktop
- Ollama
- n8n

---

### 2ï¸âƒ£ Pull LLM Model

```bash
ollama pull mistral
```

---

### 3ï¸âƒ£ Start Ollama

```bash
ollama serve
```

---

### 4ï¸âƒ£ Start n8n via Docker

```bash
docker compose up -d
```

---

### 5ï¸âƒ£ Import Workflow

- Open http://localhost:5678
- Import `workflow.json`
- Execute workflow

---

## ğŸ“‚ Project Structure

```
ai-agent-wikipedia-n8n/
â”‚
â”œâ”€â”€ workflow.json
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ README.md
â””â”€â”€ screenshots/
    â”œâ”€â”€ workflow.png
    â””â”€â”€ ollama-mistral-model-output.png
```

---

## ğŸ¯ Key Features

- Local LLM execution (no OpenAI API required)
- Custom LangChain LLM Chain Node
- Custom Tool Integration
- Autonomous AI Agent decision-making
- Dockerized deployment
- Modular architecture

---

## ğŸ’¡ Example Query

```
What year was Isaac Newton born?
```

### Example Output

```
Isaac Newton was born on January 4, 1643 (Gregorian calendar).
```

---

## ğŸ”¥ Why This Project Matters

This project demonstrates:

- AI workflow automation
- Agent-based reasoning systems
- Tool-augmented LLM architecture
- Production-style local deployment
- LangChain integration inside n8n

It reflects practical AI system design beyond simple API calls.

---

## ğŸ“Œ Future Enhancements

- Add PDF ingestion tool
- Add Resumeâ€“JD matching capability
- Add memory persistence
- Deploy to cloud (AWS / GCP)
- Add vector database (FAISS / Chroma)

---

## ğŸ‘©â€ğŸ’» Author

**Hardhika Matta**  
AI & ML | Automation | LLM Systems | AI Product Management

---

â­ If you found this interesting, feel free to star the repository!
